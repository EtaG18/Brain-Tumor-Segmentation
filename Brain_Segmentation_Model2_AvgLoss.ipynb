{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1pyCuJpuYGzGocUHi-ueTuuBNh2OocM60","authorship_tag":"ABX9TyMjd8ba6a8DX63Hqpn4ALQk"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":5,"metadata":{"id":"d45vDh6vIkLm","executionInfo":{"status":"ok","timestamp":1678781470519,"user_tz":-330,"elapsed":739,"user":{"displayName":"Achyuth Kasyap","userId":"12117926900346930702"}}},"outputs":[],"source":["import torch\n","torch.cuda.empty_cache()\n","## Importing the necessary packages and initialising various parameters ##\n","import torch\n","import os\n","from torch.utils.data import Dataset\n","import cv2\n","from torch.nn import ConvTranspose2d\n","from torch.nn import Conv2d\n","from torch.nn import MaxPool2d\n","from torch.nn import Module\n","from torch.nn import ModuleList\n","from torch.nn import ReLU\n","from torchvision.transforms import CenterCrop\n","from torch.nn import functional as F\n","from torch.nn import BCEWithLogitsLoss\n","from torch.optim import Adam\n","from torch.utils.data import DataLoader\n","from sklearn.model_selection import train_test_split\n","from torchvision import transforms\n","from imutils import paths\n","from tqdm import tqdm\n","import matplotlib.pyplot as plt\n","import time\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import albumentations as A\n","from albumentations.pytorch import ToTensorV2\n","from skimage.io import imread, imsave\n","from skimage.transform import resize\n","import torchvision\n","import torchvision.transforms.functional as G\n","from google.colab.patches import cv2_imshow\n","import torchvision.transforms.functional as TF\n","\n","# define the number of channels in the input and number of levels in the U-Net model\n","Num_channels = 3\n","\n","# Initializing learning rate, number of epochs to train and the batch size\n","Learning_rate= 0.01\n","Number_of_epochs = 20\n","Batch_size = 4\n","\n","# Define threshold to filter weak predictions\n","Threshold= 0.5\n","\n","#Input image dimensions\n","Input_image_width = 650\n","Input_image_height = 650\n","\n","\n","#Define the test split\n","Test_split= 0.15\n","\n","#Determine the device to be used for training and evaluation\n","Device= \"cuda\" if torch.cuda.is_available() else \"cpu\""]},{"cell_type":"code","source":["## Dataset loading ##\n","\n","\n","# Transformations of the image to desired size and convert to tensor\n","transforms = transforms.Compose([transforms.ToPILImage(),transforms.Resize((128,128)),transforms.RandomHorizontalFlip(p=0.8),transforms.ToTensor()]) \n","\n","\n","class SegmentationDataset(Dataset):\n","\tdef __init__(self, imagePaths, maskPaths, transforms):\n","\t\t# store the image and mask filepaths, and augmentation transforms\n","\t\tself.imagePaths = imagePaths\n","\t\tself.maskPaths = maskPaths\n","\t\tself.transforms = transforms\n","\n","\tdef __len__(self):\n","\t\t# return the number of total samples contained in the dataset\n","\t\treturn len(self.imagePaths)\n","\t\n","\tdef __getitem__(self, idx):\n","\t\timagePath = self.imagePaths[idx]  # grab the image path from the current index\n","\t\tmaskPath=self.maskPaths[idx]\n","\t\timage = cv2.imread(imagePath)\n","\t\tmask = cv2.imread(maskPath,0)\n","\t # check to see if we are applying any transformations\n","\t\tif self.transforms is not None:\n","\t\t\timage = self.transforms(image) # apply the transformations to both image and its mask\n","\t\t\tmask = self.transforms(mask)\n","\t\t# return a tuple of the image and its mask\n","\t\treturn (image, mask)\n","\n","\n","# load the image and mask filepaths in a sorted manner\n","imagePaths = sorted(list(paths.list_images('/content/drive/MyDrive/IIIT /Brain_Hemorrage_Dataset/Segmentation/Image')))\n","maskPaths = sorted(list(paths.list_images('/content/drive/MyDrive/IIIT /Brain_Hemorrage_Dataset/Segmentation/Mask')))\n","# partition the data into training and testing splits using 85% of the data for training and the remaining 15% for testing\n","split = train_test_split(imagePaths, maskPaths,test_size=0.15, random_state=42)\n","# unpack the data split\n","(trainImages, testImages) = split[:2]\n","(trainMasks, testMasks) = split[2:]\n","\n","\n","# create the train and test datasets\n","trainDS = SegmentationDataset(imagePaths=trainImages, maskPaths=trainMasks,transforms=transforms)\n","testDS = SegmentationDataset(imagePaths=testImages, maskPaths=testMasks,transforms=transforms)\n","\n","print(f\"[INFO] found {len(trainDS)} examples in the training set...\")\n","print(f\"[INFO] found {len(testDS)} examples in the test set...\")\n","\n","# create the training and test data loaders\n","trainLoader = DataLoader(trainDS, shuffle=True,batch_size=Batch_size,num_workers=os.cpu_count())\n","testLoader = DataLoader(testDS, shuffle=False,batch_size=Batch_size,num_workers=os.cpu_count())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vQDLeukJIz8q","executionInfo":{"status":"ok","timestamp":1678781470522,"user_tz":-330,"elapsed":14,"user":{"displayName":"Achyuth Kasyap","userId":"12117926900346930702"}},"outputId":"f3401230-24c2-4d2a-cb39-44996e66dd19"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["[INFO] found 249 examples in the training set...\n","[INFO] found 44 examples in the test set...\n"]}]},{"cell_type":"code","source":["import torch.nn as nn\n","import torch.nn.functional as F\n","\n","\n","class DoubleConv(nn.Module):\n","    \"\"\"(convolution => [BN] => ReLU) * 2\"\"\"\n","\n","    def __init__(self, in_channels, out_channels, mid_channels=None):\n","        super().__init__()\n","        if not mid_channels:\n","            mid_channels = out_channels\n","        self.double_conv = nn.Sequential(\n","            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1, bias=False),\n","            nn.BatchNorm2d(mid_channels),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1, bias=False),\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(inplace=True)\n","        )\n","\n","    def forward(self, x):\n","        return self.double_conv(x)\n","\n","\n","class Down(nn.Module):\n","    \"\"\"Downscaling with maxpool then double conv\"\"\"\n","\n","    def __init__(self, in_channels, out_channels):\n","        super().__init__()\n","        self.maxpool_conv = nn.Sequential(\n","            nn.MaxPool2d(2),\n","            DoubleConv(in_channels, out_channels)\n","        )\n","\n","    def forward(self, x):\n","        return self.maxpool_conv(x)\n","\n","\n","class Up(nn.Module):\n","    \"\"\"Upscaling then double conv\"\"\"\n","\n","    def __init__(self, in_channels, out_channels, bilinear=True):\n","        super().__init__()\n","\n","        # if bilinear, use the normal convolutions to reduce the number of channels\n","        if bilinear:\n","            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n","            self.conv = DoubleConv(in_channels, out_channels, in_channels // 2)\n","        else:\n","            self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n","            self.conv = DoubleConv(in_channels, out_channels)\n","\n","    def forward(self, x1, x2):\n","        x1 = self.up(x1)\n","        # input is CHW\n","        diffY = x2.size()[2] - x1.size()[2]\n","        diffX = x2.size()[3] - x1.size()[3]\n","\n","        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n","                        diffY // 2, diffY - diffY // 2])\n","        x = torch.cat([x2, x1], dim=1)\n","        return self.conv(x)\n","\n","\n","class OutConv(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super(OutConv, self).__init__()\n","        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n","\n","    def forward(self, x):\n","        return self.conv(x)\n","\n","class UNet(nn.Module):\n","    def __init__(self, n_channels, n_classes, bilinear=False):\n","        super(UNet, self).__init__()\n","        self.n_channels = n_channels\n","        self.n_classes = n_classes\n","        self.bilinear = bilinear\n","\n","        self.inc = (DoubleConv(n_channels, 64))\n","        self.down1 = (Down(64, 128))\n","        self.down2 = (Down(128, 256))\n","        self.down3 = (Down(256, 512))\n","        factor = 2 if bilinear else 1\n","        self.down4 = (Down(512, 1024 // factor))\n","        self.up1 = (Up(1024, 512 // factor, bilinear))\n","        self.up2 = (Up(512, 256 // factor, bilinear))\n","        self.up3 = (Up(256, 128 // factor, bilinear))\n","        self.up4 = (Up(128, 64, bilinear))\n","        self.outc = (OutConv(64, n_classes))\n","\n","    def forward(self, x):\n","        x1 = self.inc(x)\n","        x2 = self.down1(x1)\n","        x3 = self.down2(x2)\n","        x4 = self.down3(x3)\n","        x5 = self.down4(x4)\n","        x = self.up1(x5, x4)\n","        x = self.up2(x, x3)\n","        x = self.up3(x, x2)\n","        x = self.up4(x, x1)\n","        logits = self.outc(x)\n","        logits=torch.sigmoid(logits)\n","        return logits\n","\n","    def use_checkpointing(self):\n","        self.inc = torch.utils.checkpoint(self.inc)\n","        self.down1 = torch.utils.checkpoint(self.down1)\n","        self.down2 = torch.utils.checkpoint(self.down2)\n","        self.down3 = torch.utils.checkpoint(self.down3)\n","        self.down4 = torch.utils.checkpoint(self.down4)\n","        self.up1 = torch.utils.checkpoint(self.up1)\n","        self.up2 = torch.utils.checkpoint(self.up2)\n","        self.up3 = torch.utils.checkpoint(self.up3)\n","        self.up4 = torch.utils.checkpoint(self.up4)\n","        self.outc = torch.utils.checkpoint(self.outc)\n","\n","\n","class DiceLoss(Module):\n","    def __init__(self, weight=None, size_average=True):\n","        super(DiceLoss, self).__init__()\n","\n","    def forward(self, inputs, targets, smooth=1):\n","        \n","        #comment out if your model contains a sigmoid or equivalent activation layer\n","        #inputs = torch.sigmoid(inputs)       \n","        \n","        #flatten label and prediction tensors\n","        inputs = inputs.view(-1)\n","        targets = targets.view(-1)\n","        \n","        intersection = (inputs * targets).sum()                            \n","        dice_loss = 1-(2.*intersection + smooth)/(inputs.sum() + targets.sum() + smooth)  \n","        \n","        return dice_loss\n","\n","class IoULoss(Module):\n","    def __init__(self, weight=None, size_average=True):\n","        super(IoULoss, self).__init__()\n","\n","    def forward(self, inputs, targets, smooth=1):\n","        \n","        #comment out if your model contains a sigmoid or equivalent activation layer\n","        #inputs = torch.sigmoid(inputs)       \n","        \n","        #flatten label and prediction tensors\n","        inputs = inputs.view(-1)\n","        targets = targets.view(-1)\n","        \n","        #intersection is equivalent to True Positive count\n","        #union is the mutually inclusive area of all labels & predictions \n","        intersection = (inputs * targets).sum()\n","        total = (inputs + targets).sum()\n","        union = total - intersection \n","        \n","        IoU = (intersection + smooth)/(union + smooth)\n","                \n","        return 1 - IoU"],"metadata":{"id":"ZZ_A3bDWI3-f","executionInfo":{"status":"ok","timestamp":1678781470522,"user_tz":-330,"elapsed":11,"user":{"displayName":"Achyuth Kasyap","userId":"12117926900346930702"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["## Running the Model ##\n","\n","#For calculating the average loss \n","trainSteps = len(trainDS) // Batch_size\n","testSteps = len(testDS) // Batch_size\n","# Initializing the UNet model\n","UNet = UNet(3,1).to(Device)\n","# Initializing Loss function and Optimizer\n","DiceFunc=DiceLoss()\n","IoUFunc=IoULoss()\n","optimizer = Adam(UNet.parameters(), lr=Learning_rate)\n","# initialize a dictionary to store training history\n","H = {\"Dice_Loss\": [] , \"IOU_Loss\": []}\n","\n","\n","print(\"Training the network...\")\n","startTime = time.time()\n","for e in tqdm(range(Number_of_epochs)):\n","  UNet.train()\n","  Total_Train_Dice_Loss=0\n","  Total_Test_Dice_Loss=0\n","  Total_IoU_Loss=0\n","  for (i, (x, y)) in enumerate(trainLoader):\n","    (x, y) = (x.to(Device), y.to(Device))\n","    prediction = UNet(x)\n","    Train_Dice_Loss=DiceFunc(prediction,y)\n","    IoU_Loss=IoUFunc(prediction,y)\n","    Total_Train_Dice_Loss+=Train_Dice_Loss\n","    Total_IoU_Loss+=IoU_Loss\n","    optimizer.zero_grad()\n","    Train_Dice_Loss.backward()\n","    optimizer.step()\n","\n","  with torch.no_grad():\n","    UNet.eval()\n","    for (x, y) in testLoader:\n","      (x, y) = (x.to(Device), y.to(Device))\n","      pred = UNet(x)\n","      Test_Dice_Loss=0\n","      Test_Dice_Loss=DiceFunc(pred,y)\n","      Total_Test_Dice_Loss+=Test_Dice_Loss\n","      \n","\n","  avgTrainLoss = Total_Train_Dice_Loss / trainSteps\n","  avgTestLoss = Total_Test_Dice_Loss / testSteps\n","  avgIoULoss=Total_IoU_Loss /trainSteps\n","   \n","\t# update our training history\n","  H[\"Dice_Loss\"].append(avgTrainLoss.cpu().detach().numpy())\n","  H[\"IOU_Loss\"].append(avgIoULoss.cpu().detach().numpy())\n","  # print the model training and validation information\n","  print(\"Epoch: {}/{}\".format(e + 1, Number_of_epochs))\n","  print(\"Train Dice Loss: {:.4f}, Test Dice Loss: {:.4f},IOU Loss: {:.4f} \".format(avgTrainLoss,avgTestLoss,avgIoULoss))\n","endTime = time.time()\n","print(\"[INFO] total time taken to train the model: {:.2f}s\".format(endTime - startTime))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iktolUz3I6IG","outputId":"92db241d-774c-4890-afca-142e24bc46d8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training the network...\n"]},{"output_type":"stream","name":"stderr","text":["  5%|â–Œ         | 1/20 [07:52<2:29:43, 472.82s/it]"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1/20\n","Train Dice Loss: 0.9671, Test Dice Loss: 0.9445,IOU Loss: 0.9903 \n"]}]},{"cell_type":"code","source":["## Plotting the training loss ##\n","\n","plt.style.use(\"ggplot\")\n","plt.figure()\n","plt.plot(H[\"Dice_Loss\"], label=\"Dice Score\")\n","plt.plot(H[\"IOU_Loss\"], label=\"IOU\")\n","plt.title(\"Training Loss on Dataset\")\n","plt.xlabel(\"Epoch \")\n","plt.ylabel(\"Loss\")\n","plt.legend(loc=\"lower left\")"],"metadata":{"id":"ovH16eUEI8ev"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#define augmentations \n","inference_transform = A.Compose([\n","    A.Resize(650, 650),\n","    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),ToTensorV2()])\n","\n","#define function for predictions\n","def predict(model, img, device):\n","    model.eval()\n","    with torch.no_grad():\n","        images = img.to(device)\n","        output = model(images)\n","        # output=torch.sigmoid(output)\n","        print(output)\n","        print('Max=',torch.max(output))\n","        print('Min=',torch.min(output))\n","        predicted_masks = (output.squeeze() >= 0.5).float().cpu().numpy()\n","        \n","    return(predicted_masks)\n","\n","#define function to load image and output mask\n","def get_mask(img_path):\n","    image = cv2.imread(img_path)\n","    original_height, original_width = tuple(image.shape[:2])\n","    \n","    image_trans = inference_transform(image = image)\n","    image_trans = image_trans[\"image\"]\n","    image_trans = image_trans.unsqueeze(0)\n","    \n","    image_mask = predict(UNet, image_trans, Device)\n","        \n","    return(image_mask)"],"metadata":{"id":"3sSJGFj5I-jO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#image example\n","\n","Image_path = \"/content/drive/MyDrive/Various Datasets/Brain_Hemmorage_Segmentation_Data/Image/49.jpg\"\n","Image = cv2.imread(Image_path)\n","Image = cv2.resize(Image, (325,325))   \n","\n","Ground_truth_path= \"/content/drive/MyDrive/Various Datasets/Brain_Hemmorage_Segmentation_Data/Mask/49.jpg\"\n","Ground_truth= cv2.imread(Ground_truth_path)\n","Ground_truth = cv2.resize(Ground_truth, (325,325))   \n","\n","predicted_mask = get_mask(Image_path)\n","predicted_mask = cv2.resize(predicted_mask, (325,325))   \n","\n","print('Image')\n","cv2_imshow(Image)\n","\n","print('Ground Truth')\n","cv2_imshow(Ground_truth)\n","\n","print('Predicted Mask')\n","predicted=np.where(predicted_mask>0.1,1,0)\n","plt.imshow(predicted_mask)"],"metadata":{"id":"rzgsx6gPJAix"},"execution_count":null,"outputs":[]}]}